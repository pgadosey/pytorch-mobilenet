{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeedingUpCNNs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgadosey/pytorch-mobilenet/blob/master/SpeedingUpCNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "B_wZqs-xMKNE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Speeding up Convolutional Neural Networks\n",
        "\n",
        ">>>![](https://cdn-images-1.medium.com/max/716/1*FjzcTRoe-R680V0hOwYo5A.png)\n",
        "\n",
        ">>>>> From “Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition” paper\n",
        "\n",
        "This notebook is meant to support [this](https://medium.com/@alexburlacu1996/speeding-up-neural-networks-convolutions-240beac5e30f) blog post with concrete examples."
      ]
    },
    {
      "metadata": {
        "id": "LoraimCbPrg2",
        "colab_type": "code",
        "outputId": "cbe63ab4-cad4-4208-d850-a43ee60db214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras as _k\n",
        "\n",
        "print(f\"Keras version: {_k.__version__}\")\n",
        "print(f\"Tensorflow version: {tf.__version__}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras version: 2.1.6\n",
            "Tensorflow version: 1.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MZOhEalmhUbe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models\n",
        "\n",
        "The notebook explains how different methods of speeding up the convolutional layers work and their effect on a LeNet inspired model and an All-CNN-C model."
      ]
    },
    {
      "metadata": {
        "id": "t3DPMsrOobzu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.layers import Conv2D, Activation, Lambda, Conv3D, BatchNormalization\n",
        "\n",
        "\n",
        "ExpandDimension = lambda axis: Lambda(lambda x: K.expand_dims(x, axis))\n",
        "SqueezeDimension = lambda axis: Lambda(lambda x: K.squeeze(x, axis))\n",
        "\n",
        "# Layers\n",
        "def simple_factorized_conv(filters, kernel, *args, **kwargs):\n",
        "    kwargs[\"activation\"] = None\n",
        "    def __inner(inp):\n",
        "        cnn1 = Conv2D(filters, (kernel[0], 1), *args, **kwargs)(inp)\n",
        "        cnn2 = Conv2D(filters, (1, kernel[1]), *args, **kwargs)(cnn1)\n",
        "        \n",
        "        return cnn2\n",
        "\n",
        "    return __inner\n",
        "  \n",
        "def cp_decomposed_conv(filters, kernel, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Beware, it doesn't work! It's just an aproximate demostration of how\n",
        "    CP decomposition should be implemented. The issue is in the dimension matching.\n",
        "    If you found the solution, feel free to comment it, either in the blogpost or here.\n",
        "    You'll get full credit for your finding.\n",
        "    \"\"\"\n",
        "    kwargs[\"activation\"] = None\n",
        "    rank = filters // 2\n",
        "    d = kernel[0]\n",
        "    def __inner(inp):\n",
        "        first    = Conv2D(rank, kernel_size=(1, 1), **kwargs)(inp)\n",
        "        \n",
        "        expanded = ExpandDimension(axis=1)(first)\n",
        "        mid1     = Conv3D(rank, kernel_size=(d, 1, 1), **kwargs)(expanded)\n",
        "        mid2     = Conv3D(rank, kernel_size=(1, d, 1), **kwargs)(mid1)\n",
        "        squeezed = SqueezeDimension(axis=1)(mid2)\n",
        "        \n",
        "        last     = Conv2D(filters,  kernel_size=(1, 1), **kwargs)(squeezed)\n",
        "        \n",
        "        return last\n",
        "\n",
        "    return __inner\n",
        "\n",
        "def bn_relu(layer):\n",
        "    def __inner(*args, **kwargs):\n",
        "        l = layer(*args, **kwargs)\n",
        "        bn = BatchNormalization()(l)\n",
        "        act = Activation(\"relu\")(bn)\n",
        "        \n",
        "        return bn\n",
        "\n",
        "    return __inner\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "puaMMZX9Y_Fu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Dense, Dropout, Conv2D, SeparableConv2D,\n",
        "    MaxPool2D, Flatten, GlobalAveragePooling2D\n",
        ")\n",
        "\n",
        "class BaseExampleModel:\n",
        "    def __init__(self, conv_type=\"std\"):\n",
        "        \"\"\"\n",
        "        :convtype: used as a flag to easily switch the Convolution layer implementation\n",
        "        \"\"\"\n",
        "        self.conv_layer = lambda *args, **kwargs: {\n",
        "                              \"std\": bn_relu(Conv2D(*args, **kwargs)),\n",
        "                              \"sep\": bn_relu(SeparableConv2D(*args, **kwargs)),\n",
        "                              \"cp\" : bn_relu(cp_decomposed_conv(*args, **kwargs)),\n",
        "                              \"fac\": bn_relu(simple_factorized_conv(*args, **kwargs))\n",
        "                          }[conv_type]\n",
        "        \n",
        "    def make(self, inp, nb_classes):\n",
        "        \"\"\"\n",
        "        :inp: a reference to the Keras Input layer, to easily switch the input size\n",
        "              and even the way data is fed into network\n",
        "              (via standard Keras methods or via TF Dataset API)\n",
        "        :nb_classes: for the final Dense layer\n",
        "        \"\"\"\n",
        "        NotImplemented\n",
        "\n",
        "class AllCNNLike(BaseExampleModel):\n",
        "    \"\"\"\n",
        "    isnpired from https://arxiv.org/abs/1412.6806\n",
        "    namely All-CNN-C\n",
        "    \"\"\"\n",
        "    def __init__(self, conv_type=\"std\"):\n",
        "        super().__init__(conv_type=conv_type)\n",
        "        \n",
        "    def make(self, inp, nb_classes):\n",
        "        conv1 = self.conv_layer(96, (3, 3), padding=\"same\")(inp)\n",
        "        conv2 = self.conv_layer(96, (3, 3), padding=\"same\")(conv1)\n",
        "        \n",
        "        conv3 = bn_relu(Conv2D(96, (3, 3), padding=\"same\", strides=(2, 2)))(conv2)\n",
        "        \n",
        "        conv4 = self.conv_layer(192, (3, 3), padding=\"same\")(conv3)\n",
        "        conv5 = self.conv_layer(192, (3, 3), padding=\"same\")(conv4)\n",
        "        \n",
        "        conv6 = bn_relu(Conv2D(192, (3, 3), padding=\"same\", strides=(2, 2)))(conv5)\n",
        "        \n",
        "        conv7 = bn_relu(Conv2D(192, (3, 3), padding=\"same\"))(conv6)\n",
        "        conv8 = bn_relu(Conv2D(192, (1, 1), padding=\"same\"))(conv7)\n",
        "        conv9 = bn_relu(Conv2D(nb_classes, (1, 1), padding=\"same\"))(conv8)\n",
        "        \n",
        "        gap = GlobalAveragePooling2D()(conv9)\n",
        "        final = Activation(\"softmax\")(gap)\n",
        "        \n",
        "        return Model(inputs=inp, outputs=final)\n",
        "      \n",
        "class WiderAllCNNLike(BaseExampleModel):\n",
        "    \"\"\"\n",
        "    isnpired from https://arxiv.org/abs/1412.6806\n",
        "    namely All-CNN-C\n",
        "    \"\"\"\n",
        "    def __init__(self, conv_type=\"std\"):\n",
        "        super().__init__(conv_type=conv_type)\n",
        "        \n",
        "    def make(self, inp, nb_classes):\n",
        "        conv1 = self.conv_layer(192, (3, 3), padding=\"same\")(inp)\n",
        "        \n",
        "        conv2 = bn_relu(Conv2D(96, (3, 3), padding=\"same\", strides=(2, 2)))(conv1)\n",
        "        \n",
        "        conv3 = self.conv_layer(384, (3, 3), padding=\"same\")(conv2)\n",
        "        \n",
        "        conv4 = bn_relu(Conv2D(128, (3, 3), padding=\"same\", strides=(2, 2)))(conv3)\n",
        "        \n",
        "        conv5 = bn_relu(Conv2D(256, (3, 3), padding=\"same\"))(conv4)\n",
        "        conv6 = bn_relu(Conv2D(nb_classes, (1, 1), padding=\"same\"))(conv5)\n",
        "        \n",
        "        gap = GlobalAveragePooling2D()(conv6)\n",
        "        final = Activation(\"softmax\")(gap)\n",
        "        \n",
        "        return Model(inputs=inp, outputs=final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GNR22H8hwdgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess_data(pair):\n",
        "    x, y = pair\n",
        "    return x / 255., to_categorical(y)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = map(preprocess_data, cifar100.load_data())\n",
        "\n",
        "train_gen = ImageDataGenerator().flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "test_gen = ImageDataGenerator().flow(x_test, y_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PfgyShr7e3Ut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "from keras.optimizers import  SGD\n",
        "from keras.layers import Input\n",
        "\n",
        "def main(conv_type=\"std\", verbose=False, net_type=\"simple\"):\n",
        "    inp = Input(shape=(32, 32, 3))\n",
        "    net = {\n",
        "        \"simple\": AllCNNLike(conv_type=conv_type).make(inp, nb_classes=100),\n",
        "        \"wide\": WiderAllCNNLike(conv_type=conv_type).make(inp, nb_classes=100)\n",
        "    }[net_type]\n",
        "\n",
        "    net.compile(SGD(lr=0.01, decay=0.001, momentum=0.8), \"categorical_crossentropy\",\n",
        "                 metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
        "\n",
        "    if verbose:\n",
        "        print(net.summary())\n",
        "\n",
        "    net.fit_generator(train_gen, steps_per_epoch=50000 // BATCH_SIZE, epochs=5, verbose=verbose)\n",
        "    loss, acc, topk_acc = net.evaluate_generator(test_gen, steps=10000 // BATCH_SIZE)\n",
        "\n",
        "    print(f\"Accuracy: {acc}, Top5 Accuracy {topk_acc} and Loss {loss}.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pwq5PiO54oi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Standard Convolutions"
      ]
    },
    {
      "metadata": {
        "id": "C7BIk1qgw6kg",
        "colab_type": "code",
        "outputId": "094f3d06-09f4-4ad3-cd14-27f4297055f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1150
        }
      },
      "cell_type": "code",
      "source": [
        "# Run it!\n",
        "main(\"std\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 96)        2688      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 16, 16, 192)       166080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 192)       331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 8, 8, 192)         37056     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 100)         19300     \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 1,392,500\n",
            "Trainable params: 1,389,804\n",
            "Non-trainable params: 2,696\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
            "Epoch 1/5\n",
            "  26/1562 [..............................] - ETA: 3:43 - loss: 4.5335 - categorical_accuracy: 0.0337 - top_k_categorical_accuracy: 0.1178"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 756/1562 [=============>................] - ETA: 48s - loss: 4.2137 - categorical_accuracy: 0.0740 - top_k_categorical_accuracy: 0.2384"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1491/1562 [===========================>..] - ETA: 4s - loss: 4.1584 - categorical_accuracy: 0.0817 - top_k_categorical_accuracy: 0.2596"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 91s 58ms/step - loss: 4.1547 - categorical_accuracy: 0.0822 - top_k_categorical_accuracy: 0.2606\n",
            "Epoch 2/5\n",
            " 312/1562 [====>.........................] - ETA: 1:10 - loss: 4.0689 - categorical_accuracy: 0.1015 - top_k_categorical_accuracy: 0.2948"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1044/1562 [===================>..........] - ETA: 29s - loss: 4.0462 - categorical_accuracy: 0.1035 - top_k_categorical_accuracy: 0.3005"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 89s 57ms/step - loss: 4.0352 - categorical_accuracy: 0.1047 - top_k_categorical_accuracy: 0.3026\n",
            "Epoch 3/5\n",
            " 101/1562 [>.............................] - ETA: 1:22 - loss: 4.0075 - categorical_accuracy: 0.1064 - top_k_categorical_accuracy: 0.3072"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 833/1562 [==============>...............] - ETA: 41s - loss: 3.9942 - categorical_accuracy: 0.1104 - top_k_categorical_accuracy: 0.3170"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 89s 57ms/step - loss: 3.9882 - categorical_accuracy: 0.1115 - top_k_categorical_accuracy: 0.3193\n",
            "Epoch 4/5\n",
            "   2/1562 [..............................] - ETA: 1:35 - loss: 3.9989 - categorical_accuracy: 0.1094 - top_k_categorical_accuracy: 0.3750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 732/1562 [=============>................] - ETA: 47s - loss: 3.9670 - categorical_accuracy: 0.1200 - top_k_categorical_accuracy: 0.3256"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1467/1562 [===========================>..] - ETA: 5s - loss: 3.9596 - categorical_accuracy: 0.1204 - top_k_categorical_accuracy: 0.3268"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 90s 57ms/step - loss: 3.9590 - categorical_accuracy: 0.1203 - top_k_categorical_accuracy: 0.3267\n",
            "Epoch 5/5\n",
            " 300/1562 [====>.........................] - ETA: 1:11 - loss: 3.9577 - categorical_accuracy: 0.1170 - top_k_categorical_accuracy: 0.3214"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1032/1562 [==================>...........] - ETA: 30s - loss: 3.9419 - categorical_accuracy: 0.1221 - top_k_categorical_accuracy: 0.3330"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 89s 57ms/step - loss: 3.9379 - categorical_accuracy: 0.1231 - top_k_categorical_accuracy: 0.3336\n",
            "Accuracy: 0.13661858974358973, Top5 Accuracy 0.34705528846153844 and Loss 3.91607553148881.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yn1fY9pR6BaE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simply Factorized Convolutions"
      ]
    },
    {
      "metadata": {
        "id": "CvAky1jN6Nno",
        "colab_type": "code",
        "outputId": "ed697122-d325-4034-96a0-6d33e419b838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1275
        }
      },
      "cell_type": "code",
      "source": [
        "# You know what to do ;)\n",
        "main(\"fac\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 32, 32, 96)        960       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 32, 32, 96)        27744     \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 96)        27744     \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 32, 32, 96)        27744     \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 16, 16, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 16, 16, 192)       55488     \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 16, 16, 192)       110784    \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 16, 16, 192)       110784    \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 16, 16, 192)       110784    \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 8, 8, 192)         37056     \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 8, 8, 100)         19300     \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 1,280,756\n",
            "Trainable params: 1,278,060\n",
            "Non-trainable params: 2,696\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "  24/1562 [..............................] - ETA: 3:37 - loss: 4.5389 - categorical_accuracy: 0.0260 - top_k_categorical_accuracy: 0.1133"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 753/1562 [=============>................] - ETA: 58s - loss: 4.2273 - categorical_accuracy: 0.0766 - top_k_categorical_accuracy: 0.2366"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1487/1562 [===========================>..] - ETA: 5s - loss: 4.1671 - categorical_accuracy: 0.0849 - top_k_categorical_accuracy: 0.2588"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 111s 71ms/step - loss: 4.1641 - categorical_accuracy: 0.0852 - top_k_categorical_accuracy: 0.2601\n",
            "Epoch 2/5\n",
            " 308/1562 [====>.........................] - ETA: 1:27 - loss: 4.0709 - categorical_accuracy: 0.1005 - top_k_categorical_accuracy: 0.2982"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1039/1562 [==================>...........] - ETA: 36s - loss: 4.0453 - categorical_accuracy: 0.1016 - top_k_categorical_accuracy: 0.3008"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 109s 70ms/step - loss: 4.0372 - categorical_accuracy: 0.1045 - top_k_categorical_accuracy: 0.3028\n",
            "Epoch 3/5\n",
            "  99/1562 [>.............................] - ETA: 1:42 - loss: 3.9916 - categorical_accuracy: 0.1130 - top_k_categorical_accuracy: 0.3157"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 829/1562 [==============>...............] - ETA: 51s - loss: 3.9962 - categorical_accuracy: 0.1101 - top_k_categorical_accuracy: 0.3157"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 109s 70ms/step - loss: 3.9916 - categorical_accuracy: 0.1116 - top_k_categorical_accuracy: 0.3166\n",
            "Epoch 4/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 729/1562 [=============>................] - ETA: 59s - loss: 3.9795 - categorical_accuracy: 0.1168 - top_k_categorical_accuracy: 0.3194"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1463/1562 [===========================>..] - ETA: 6s - loss: 3.9651 - categorical_accuracy: 0.1193 - top_k_categorical_accuracy: 0.3270"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 110s 71ms/step - loss: 3.9655 - categorical_accuracy: 0.1195 - top_k_categorical_accuracy: 0.3267\n",
            "Epoch 5/5\n",
            " 297/1562 [====>.........................] - ETA: 1:28 - loss: 3.9503 - categorical_accuracy: 0.1185 - top_k_categorical_accuracy: 0.3282"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1028/1562 [==================>...........] - ETA: 37s - loss: 3.9489 - categorical_accuracy: 0.1191 - top_k_categorical_accuracy: 0.3277"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 110s 70ms/step - loss: 3.9442 - categorical_accuracy: 0.1200 - top_k_categorical_accuracy: 0.3298\n",
            "Accuracy: 0.1273036858974359, Top5 Accuracy 0.33543669871794873 and Loss 3.939175302401567.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r59tSSuw6SXo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dephwise Separable Convolutions"
      ]
    },
    {
      "metadata": {
        "id": "P-_AEPNq6WpU",
        "colab_type": "code",
        "outputId": "3e01e20a-8f84-4c11-ac03-b6709da25ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1132
        }
      },
      "cell_type": "code",
      "source": [
        "# Push that button!\n",
        "main(\"sep\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_19 (Separab (None, 32, 32, 96)        411       \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_20 (Separab (None, 32, 32, 96)        10176     \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 16, 16, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_21 (Separab (None, 16, 16, 192)       19488     \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_22 (Separab (None, 16, 16, 192)       38784     \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 8, 8, 192)         37056     \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 8, 8, 100)         19300     \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_6 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 877,583\n",
            "Trainable params: 874,887\n",
            "Non-trainable params: 2,696\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "  39/1562 [..............................] - ETA: 2:30 - loss: 4.5162 - categorical_accuracy: 0.0304 - top_k_categorical_accuracy: 0.1138"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1363/1562 [=========================>....] - ETA: 9s - loss: 4.1763 - categorical_accuracy: 0.0837 - top_k_categorical_accuracy: 0.2572"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 73s 47ms/step - loss: 4.1638 - categorical_accuracy: 0.0852 - top_k_categorical_accuracy: 0.2611\n",
            "Epoch 2/5\n",
            " 546/1562 [=========>....................] - ETA: 46s - loss: 4.0528 - categorical_accuracy: 0.1035 - top_k_categorical_accuracy: 0.3019"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 71s 46ms/step - loss: 4.0402 - categorical_accuracy: 0.1054 - top_k_categorical_accuracy: 0.3054\n",
            "Epoch 3/5\n",
            " 153/1562 [=>............................] - ETA: 1:03 - loss: 3.9979 - categorical_accuracy: 0.1148 - top_k_categorical_accuracy: 0.3172"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1525/1562 [============================>.] - ETA: 1s - loss: 3.9947 - categorical_accuracy: 0.1145 - top_k_categorical_accuracy: 0.3175"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 71s 45ms/step - loss: 3.9945 - categorical_accuracy: 0.1147 - top_k_categorical_accuracy: 0.3176\n",
            "Epoch 4/5\n",
            " 626/1562 [===========>..................] - ETA: 42s - loss: 3.9712 - categorical_accuracy: 0.1210 - top_k_categorical_accuracy: 0.3266"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 71s 45ms/step - loss: 3.9656 - categorical_accuracy: 0.1205 - top_k_categorical_accuracy: 0.3289\n",
            "Epoch 5/5\n",
            " 204/1562 [==>...........................] - ETA: 1:01 - loss: 3.9374 - categorical_accuracy: 0.1244 - top_k_categorical_accuracy: 0.3441"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 71s 45ms/step - loss: 3.9440 - categorical_accuracy: 0.1260 - top_k_categorical_accuracy: 0.3365\n",
            "Accuracy: 0.13481570512820512, Top5 Accuracy 0.33764022435897434 and Loss 3.9103850561838884.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3P-8Gjxw9f-W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wide Standard Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "ZDeWv06C9e2e",
        "colab_type": "code",
        "outputId": "2566b876-2602-4198-b2fe-ce1e7d8a5e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "cell_type": "code",
      "source": [
        "main(\"std\", net_type=\"wide\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 32, 32, 192)       5376      \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 32, 32, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 16, 16, 96)        165984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_67 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 16, 16, 384)       332160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_68 (Batc (None, 16, 16, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 8, 8, 128)         442496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_69 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_70 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 8, 8, 100)         25700     \n",
            "_________________________________________________________________\n",
            "batch_normalization_71 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_9 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_80 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 1,271,508\n",
            "Trainable params: 1,269,196\n",
            "Non-trainable params: 2,312\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "  60/1562 [>.............................] - ETA: 2:05 - loss: 4.4673 - categorical_accuracy: 0.0276 - top_k_categorical_accuracy: 0.1276"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1434/1562 [==========================>...] - ETA: 6s - loss: 4.2004 - categorical_accuracy: 0.0800 - top_k_categorical_accuracy: 0.2447"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 74s 47ms/step - loss: 4.1937 - categorical_accuracy: 0.0805 - top_k_categorical_accuracy: 0.2470\n",
            "Epoch 2/5\n",
            " 588/1562 [==========>...................] - ETA: 44s - loss: 4.0982 - categorical_accuracy: 0.0950 - top_k_categorical_accuracy: 0.2790"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 72s 46ms/step - loss: 4.0822 - categorical_accuracy: 0.0969 - top_k_categorical_accuracy: 0.2869\n",
            "Epoch 3/5\n",
            " 194/1562 [==>...........................] - ETA: 1:03 - loss: 4.0470 - categorical_accuracy: 0.1029 - top_k_categorical_accuracy: 0.2954"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1560/1562 [============================>.] - ETA: 0s - loss: 4.0390 - categorical_accuracy: 0.1058 - top_k_categorical_accuracy: 0.3018"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1562/1562 [==============================] - 72s 46ms/step - loss: 4.0391 - categorical_accuracy: 0.1058 - top_k_categorical_accuracy: 0.3018\n",
            "Epoch 4/5\n",
            " 436/1562 [=======>......................] - ETA: 52s - loss: 4.0135 - categorical_accuracy: 0.1077 - top_k_categorical_accuracy: 0.3117"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 72s 46ms/step - loss: 4.0135 - categorical_accuracy: 0.1078 - top_k_categorical_accuracy: 0.3104\n",
            "Epoch 5/5\n",
            " 108/1562 [=>............................] - ETA: 1:06 - loss: 3.9906 - categorical_accuracy: 0.1143 - top_k_categorical_accuracy: 0.3235"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1489/1562 [===========================>..] - ETA: 3s - loss: 3.9963 - categorical_accuracy: 0.1119 - top_k_categorical_accuracy: 0.3171"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 72s 46ms/step - loss: 3.9963 - categorical_accuracy: 0.1118 - top_k_categorical_accuracy: 0.3175\n",
            "Accuracy: 0.1233974358974359, Top5 Accuracy 0.32662259615384615 and Loss 3.9777390643572197.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X9HrLDw89wIC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wide Separable Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "63TmL7DN91yq",
        "colab_type": "code",
        "outputId": "3e7771ba-0589-41f0-a1e3-eaf81b06c9dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "cell_type": "code",
      "source": [
        "main(\"sep\", net_type=\"wide\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_35 (Separab (None, 32, 32, 192)       795       \n",
            "_________________________________________________________________\n",
            "batch_normalization_81 (Batc (None, 32, 32, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 16, 16, 96)        165984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_82 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_36 (Separab (None, 16, 16, 384)       38112     \n",
            "_________________________________________________________________\n",
            "batch_normalization_83 (Batc (None, 16, 16, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 8, 8, 128)         442496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_84 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_85 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 8, 8, 100)         25700     \n",
            "_________________________________________________________________\n",
            "batch_normalization_86 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_11  (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_97 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 972,879\n",
            "Trainable params: 970,567\n",
            "Non-trainable params: 2,312\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "  69/1562 [>.............................] - ETA: 1:52 - loss: 4.4585 - categorical_accuracy: 0.0362 - top_k_categorical_accuracy: 0.1404"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1520/1562 [============================>.] - ETA: 1s - loss: 4.1846 - categorical_accuracy: 0.0814 - top_k_categorical_accuracy: 0.2517"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 69s 44ms/step - loss: 4.1823 - categorical_accuracy: 0.0821 - top_k_categorical_accuracy: 0.2525\n",
            "Epoch 2/5\n",
            " 647/1562 [===========>..................] - ETA: 39s - loss: 4.0784 - categorical_accuracy: 0.0972 - top_k_categorical_accuracy: 0.2917"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 67s 43ms/step - loss: 4.0682 - categorical_accuracy: 0.1004 - top_k_categorical_accuracy: 0.2965\n",
            "Epoch 3/5\n",
            " 244/1562 [===>..........................] - ETA: 57s - loss: 4.0455 - categorical_accuracy: 0.1104 - top_k_categorical_accuracy: 0.3030"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 67s 43ms/step - loss: 4.0309 - categorical_accuracy: 0.1064 - top_k_categorical_accuracy: 0.3086\n",
            "Epoch 4/5\n",
            "  58/1562 [>.............................] - ETA: 1:04 - loss: 4.0265 - categorical_accuracy: 0.1051 - top_k_categorical_accuracy: 0.3098"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1503/1562 [===========================>..] - ETA: 2s - loss: 4.0093 - categorical_accuracy: 0.1122 - top_k_categorical_accuracy: 0.3133"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 67s 43ms/step - loss: 4.0080 - categorical_accuracy: 0.1119 - top_k_categorical_accuracy: 0.3138\n",
            "Epoch 5/5\n",
            " 643/1562 [===========>..................] - ETA: 39s - loss: 3.9882 - categorical_accuracy: 0.1171 - top_k_categorical_accuracy: 0.3243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 67s 43ms/step - loss: 3.9925 - categorical_accuracy: 0.1150 - top_k_categorical_accuracy: 0.3218\n",
            "Accuracy: 0.1266025641025641, Top5 Accuracy 0.33283253205128205 and Loss 3.96610679764014.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TMQuI3t493z0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wide Simply Factorized Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "P92aWTwo92vo",
        "colab_type": "code",
        "outputId": "7d11112f-7781-4e30-d253-c63a95863a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "cell_type": "code",
      "source": [
        "main(\"fac\", net_type=\"wide\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 32, 32, 192)       1920      \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 32, 32, 192)       110784    \n",
            "_________________________________________________________________\n",
            "batch_normalization_96 (Batc (None, 32, 32, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 16, 16, 96)        165984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_97 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_122 (Conv2D)          (None, 16, 16, 384)       110976    \n",
            "_________________________________________________________________\n",
            "conv2d_123 (Conv2D)          (None, 16, 16, 384)       442752    \n",
            "_________________________________________________________________\n",
            "batch_normalization_98 (Batc (None, 16, 16, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_124 (Conv2D)          (None, 8, 8, 128)         442496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_99 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_125 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_100 (Bat (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_126 (Conv2D)          (None, 8, 8, 100)         25700     \n",
            "_________________________________________________________________\n",
            "batch_normalization_101 (Bat (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_13  (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_114 (Activation)  (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 1,600,404\n",
            "Trainable params: 1,598,092\n",
            "Non-trainable params: 2,312\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "  34/1562 [..............................] - ETA: 3:49 - loss: 4.5639 - categorical_accuracy: 0.0276 - top_k_categorical_accuracy: 0.0956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 762/1562 [=============>................] - ETA: 1:02 - loss: 4.2492 - categorical_accuracy: 0.0679 - top_k_categorical_accuracy: 0.2252"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1496/1562 [===========================>..] - ETA: 5s - loss: 4.1985 - categorical_accuracy: 0.0773 - top_k_categorical_accuracy: 0.2454"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 120s 77ms/step - loss: 4.1949 - categorical_accuracy: 0.0783 - top_k_categorical_accuracy: 0.2468\n",
            "Epoch 2/5\n",
            " 313/1562 [=====>........................] - ETA: 1:33 - loss: 4.0971 - categorical_accuracy: 0.0962 - top_k_categorical_accuracy: 0.2846"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1044/1562 [===================>..........] - ETA: 38s - loss: 4.0855 - categorical_accuracy: 0.0950 - top_k_categorical_accuracy: 0.2872"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 117s 75ms/step - loss: 4.0749 - categorical_accuracy: 0.0985 - top_k_categorical_accuracy: 0.2926\n",
            "Epoch 3/5\n",
            " 101/1562 [>.............................] - ETA: 1:51 - loss: 4.0307 - categorical_accuracy: 0.1083 - top_k_categorical_accuracy: 0.3103"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 830/1562 [==============>...............] - ETA: 55s - loss: 4.0424 - categorical_accuracy: 0.1054 - top_k_categorical_accuracy: 0.3018"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 117s 75ms/step - loss: 4.0353 - categorical_accuracy: 0.1055 - top_k_categorical_accuracy: 0.3038\n",
            "Epoch 4/5\n",
            "   1/1562 [..............................] - ETA: 1:53 - loss: 3.9588 - categorical_accuracy: 0.0625 - top_k_categorical_accuracy: 0.3125"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 729/1562 [=============>................] - ETA: 1:02 - loss: 4.0187 - categorical_accuracy: 0.1089 - top_k_categorical_accuracy: 0.3087"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1464/1562 [===========================>..] - ETA: 7s - loss: 4.0098 - categorical_accuracy: 0.1092 - top_k_categorical_accuracy: 0.3128"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 117s 75ms/step - loss: 4.0102 - categorical_accuracy: 0.1094 - top_k_categorical_accuracy: 0.3122\n",
            "Epoch 5/5\n",
            " 297/1562 [====>.........................] - ETA: 1:34 - loss: 3.9895 - categorical_accuracy: 0.1142 - top_k_categorical_accuracy: 0.3209"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1027/1562 [==================>...........] - ETA: 40s - loss: 3.9977 - categorical_accuracy: 0.1123 - top_k_categorical_accuracy: 0.3162"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 117s 75ms/step - loss: 3.9905 - categorical_accuracy: 0.1143 - top_k_categorical_accuracy: 0.3197\n",
            "Accuracy: 0.11909054487179487, Top5 Accuracy 0.32401842948717946 and Loss 3.9671124288669.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kFVdAkF0dkO-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Failures aside, now a good architecture"
      ]
    },
    {
      "metadata": {
        "id": "HM158WQhdjdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AdequatelyDesignedAllCNNLike:\n",
        "    \"\"\"\n",
        "    isnpired from https://arxiv.org/abs/1412.6806\n",
        "    namely All-CNN-C\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def make(self, inp, nb_classes):\n",
        "        # the chunk below can be represented as a single layer with 5x5 kernels\n",
        "        conv1 = Conv2D(96, (3, 3), padding=\"same\")(inp)\n",
        "        bn1   = BatchNormalization()(conv1)\n",
        "        act1  = Activation(\"relu\")(bn1)\n",
        "        conv2 = Conv2D(96, (3, 3), padding=\"same\")(act1)\n",
        "        bn2   = BatchNormalization()(conv2)\n",
        "        act2  = Activation(\"relu\")(bn2)\n",
        "        \n",
        "        conv3 = Conv2D(96, (3, 3), padding=\"same\", strides=(2, 2))(act2)\n",
        "        bn3   = BatchNormalization()(conv3)\n",
        "        act3  = Activation(\"relu\")(bn3)\n",
        "        \n",
        "        conv4 = SeparableConv2D(256, (3, 3), padding=\"same\")(act3)\n",
        "        bn4   = BatchNormalization()(conv4)\n",
        "        act4  = Activation(\"relu\")(bn4)\n",
        "        \n",
        "        conv5 = Conv2D(192, (3, 3), padding=\"same\", strides=(2, 2))(act4)\n",
        "        bn5   = BatchNormalization()(conv5)\n",
        "        act5  = Activation(\"relu\")(bn5)\n",
        "        \n",
        "        conv6 = SeparableConv2D(256, (3, 3), padding=\"same\")(act5)\n",
        "        bn6   = BatchNormalization()(conv6)\n",
        "        act6  = Activation(\"relu\")(bn6)\n",
        "        \n",
        "        conv7 = Conv2D(nb_classes, (1, 1), padding=\"same\")(act6)\n",
        "        bn7   = BatchNormalization()(conv7)\n",
        "        act7  = Activation(\"relu\")(bn7)\n",
        "        \n",
        "        gap = GlobalAveragePooling2D()(act7)\n",
        "        final = Activation(\"softmax\")(gap)\n",
        "        \n",
        "        return Model(inputs=inp, outputs=final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ta-JIf4xe6-k",
        "colab_type": "code",
        "outputId": "a879bc2d-271a-496a-f9a6-588baf485521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1239
        }
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(32, 32, 3))\n",
        "net = AdequatelyDesignedAllCNNLike().make(inp, 100)\n",
        "net.compile(SGD(lr=0.01, decay=0.001, momentum=0.8), \"categorical_crossentropy\",\n",
        "             metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
        "\n",
        "\n",
        "print(net.summary())\n",
        "\n",
        "net.fit_generator(train_gen, steps_per_epoch=50000 // BATCH_SIZE, epochs=5)\n",
        "loss, acc, topk_acc = net.evaluate_generator(test_gen, steps=10000 // BATCH_SIZE)\n",
        "\n",
        "print(f\"Accuracy: {acc}, Top5 Accuracy {topk_acc} and Loss {loss}.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_127 (Conv2D)          (None, 32, 32, 96)        2688      \n",
            "_________________________________________________________________\n",
            "batch_normalization_102 (Bat (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_115 (Activation)  (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_128 (Conv2D)          (None, 32, 32, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_103 (Bat (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_116 (Activation)  (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_129 (Conv2D)          (None, 16, 16, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_104 (Bat (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_117 (Activation)  (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_43 (Separab (None, 16, 16, 256)       25696     \n",
            "_________________________________________________________________\n",
            "batch_normalization_105 (Bat (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_118 (Activation)  (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_130 (Conv2D)          (None, 8, 8, 192)         442560    \n",
            "_________________________________________________________________\n",
            "batch_normalization_106 (Bat (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_119 (Activation)  (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_44 (Separab (None, 8, 8, 256)         51136     \n",
            "_________________________________________________________________\n",
            "batch_normalization_107 (Bat (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_120 (Activation)  (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_131 (Conv2D)          (None, 8, 8, 100)         25700     \n",
            "_________________________________________________________________\n",
            "batch_normalization_108 (Bat (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_121 (Activation)  (None, 8, 8, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_14  (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_122 (Activation)  (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 718,228\n",
            "Trainable params: 716,044\n",
            "Non-trainable params: 2,184\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "  35/1562 [..............................] - ETA: 2:55 - loss: 4.5366 - categorical_accuracy: 0.0366 - top_k_categorical_accuracy: 0.1027"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1315/1562 [========================>.....] - ETA: 11s - loss: 4.0162 - categorical_accuracy: 0.1178 - top_k_categorical_accuracy: 0.3317"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 75s 48ms/step - loss: 3.9747 - categorical_accuracy: 0.1251 - top_k_categorical_accuracy: 0.3458\n",
            "Epoch 2/5\n",
            " 493/1562 [========>.....................] - ETA: 49s - loss: 3.6405 - categorical_accuracy: 0.1930 - top_k_categorical_accuracy: 0.4620"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 73s 47ms/step - loss: 3.5535 - categorical_accuracy: 0.2068 - top_k_categorical_accuracy: 0.4875\n",
            "Epoch 3/5\n",
            " 102/1562 [>.............................] - ETA: 1:07 - loss: 3.4211 - categorical_accuracy: 0.2396 - top_k_categorical_accuracy: 0.5251"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1394/1562 [=========================>....] - ETA: 7s - loss: 3.3254 - categorical_accuracy: 0.2500 - top_k_categorical_accuracy: 0.5525"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 73s 47ms/step - loss: 3.3173 - categorical_accuracy: 0.2518 - top_k_categorical_accuracy: 0.5542\n",
            "Epoch 4/5\n",
            " 525/1562 [=========>....................] - ETA: 48s - loss: 3.2006 - categorical_accuracy: 0.2679 - top_k_categorical_accuracy: 0.5852"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 73s 47ms/step - loss: 3.1602 - categorical_accuracy: 0.2810 - top_k_categorical_accuracy: 0.5942\n",
            "Epoch 5/5\n",
            " 112/1562 [=>............................] - ETA: 1:07 - loss: 3.0590 - categorical_accuracy: 0.3061 - top_k_categorical_accuracy: 0.6169"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1458/1562 [===========================>..] - ETA: 4s - loss: 3.0364 - categorical_accuracy: 0.3096 - top_k_categorical_accuracy: 0.6198"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 72s 46ms/step - loss: 3.0324 - categorical_accuracy: 0.3102 - top_k_categorical_accuracy: 0.6208\n",
            "Accuracy: 0.1837940705128205, Top5 Accuracy 0.4434094551282051 and Loss 3.6364160730288577.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ncz_LGTtxURM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Final notes\n",
        "\n",
        "As you can see, it is indeed possible with slight alterations to speed up a convolutional network like All-CNN-C by 25% (See Wide Separable Convolution) with no significant drop in accuracy.\n",
        "Moreover, with a better-designed network (See AdequatelyDesignedAllCNNLike model), the speedup is still considerable (> 15%) but the accuracy increases almost 1.5x, after the same amount of time!\n",
        "\n",
        "Anyway, remember that there's no silver bullet and you should always experiment in order to get satisfying results.\n",
        "\n",
        "Hopefully, the methods showed above and described in the blog post will help."
      ]
    }
  ]
}